# Complete System Explanation

## ğŸ¯ How Everything Works

### 1. **Dataset Processing Pipeline**

```
CSV Files (datasets/)
    â†“
data_loader.py
    â”œâ”€â”€ Reads 5 CSV files
    â”œâ”€â”€ Handles different column formats
    â”œâ”€â”€ Formats questions appropriately
    â””â”€â”€ Returns: List of {category, question, answer}
    â†“
vector_index.py
    â”œâ”€â”€ Uses SentenceTransformer to embed text
    â”œâ”€â”€ Creates 384-dimensional vectors
    â”œâ”€â”€ Builds FAISS index (L2 distance)
    â””â”€â”€ Ready for similarity search
```

**Key Points:**
- **5 datasets loaded**: gsm8k, boolq, wsc, anli, proofwriter
- **200 samples per dataset** (default, configurable)
- **Different formats handled**: Standard Q&A, premise+hypothesis, pronoun resolution, etc.
- **Vector embeddings**: Text converted to numbers for similarity comparison

### 2. **Agent Architecture**

#### Baseline Agent (Simple)
```
Question â†’ ModelClient â†’ Ollama â†’ Answer
```
- Direct path: no planning, no tools
- Fast response
- Uses same model as configurable agent

#### Configurable Agent (Multi-Stage)
```
Question
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. PLANNER                      â”‚
â”‚    Splits question into steps   â”‚
â”‚    Output: "Steps:\n1. ..."     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. TOOLS                        â”‚
â”‚    Checks for math expressions  â”‚
â”‚    If found: Uses safe_eval()   â”‚
â”‚    If not: Skip to reasoner     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. REASONER                     â”‚
â”‚    Combines: Plan + Question    â”‚
â”‚    Sends to Ollama (qwen3:8b)   â”‚
â”‚    Generates answer            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. MEMORY                       â”‚
â”‚    Stores: (question, answer)   â”‚
â”‚    Short-term session memory   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. REFLECTION                   â”‚
â”‚    Compares answer vs expected  â”‚
â”‚    Calculates similarity score  â”‚
â”‚    Provides feedback           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Final Result: {plan, answer, reflection}
```

## ğŸ”Œ Component Connections

### Model Client (`model_client.py`)
- **Purpose**: Wrapper for Ollama API
- **Connects**: Local Ollama service (localhost)
- **Used by**: 
  - `Reasoner` (configurable agent)
  - `BaselineAgent`
- **Function**: Converts prompts to Ollama API calls

### Config File (`base_config.yaml`)
- **Purpose**: Control agent behavior
- **Read by**: `ConfigurableAgent.__init__()`
- **Controls**: 
  - Which model to use
  - Feature flags (planning, reasoning, etc.)

### Vector Index (`vector_index.py`)
- **Uses**: `data_loader.load_all()` to get datasets
- **Uses**: `SentenceTransformer` for embeddings
- **Uses**: `FAISS` for fast similarity search
- **Used by**: `interactive_eval.py` to find similar examples

### Graph Logger (`graph_logger.py`)
- **Connects**: Neo4j database (optional)
- **Used by**: `interactive_eval.py` and `dashboard.py`
- **Function**: Logs runs and creates relationships

## ğŸ“Š Data Flow Example

**Example Question**: "Who was the president of USA in 2010?"

### Step 1: User Input
```
User enters question â†’ interactive_eval.py or dashboard.py
```

### Step 2: Similarity Search
```
Question â†’ vector_index.query()
    â†“
Embed question â†’ Search FAISS index
    â†“
Find top 3 similar examples
    â†“
Return: [{sample: {...}, similarity: 0.85}, ...]
```

### Step 3: Baseline Processing
```
Question â†’ BaselineAgent.run()
    â†“
ModelClient.generate("Answer briefly:\n{question}\nAnswer:")
    â†“
Ollama API call
    â†“
Answer: "Barack Obama was the president..."
```

### Step 4: Configurable Agent Processing
```
Question â†’ ConfigurableAgent.run()
    â†“
Planner.plan() â†’ "Steps:\n1. Who was the president..."
    â†“
Tools.math_tool() â†’ No math found
    â†“
Reasoner.reason(Plan + Question)
    â†“
ModelClient â†’ Ollama â†’ "Barack Obama..."
    â†“
Memory.remember(question, answer)
    â†“
Reflection.evaluate() â†’ {score: 0.8, comment: "Good"}
    â†“
Return: {plan, answer, reflection}
```

### Step 5: Evaluation
```
If expected answer provided:
    â†“
compute_bleu(predicted, expected) â†’ 0.75
compute_rouge(predicted, expected) â†’ 0.82
```

### Step 6: Logging (Optional)
```
GraphLogger.log_run()
    â†“
Neo4j database
    â†“
Creates: Run node + Example nodes + SIMILAR_TO relationships
```

### Step 7: Output
```
Display:
- Baseline answer
- Configurable agent (plan + answer + reflection)
- Metrics (BLEU, ROUGE)
- Similar examples
- Execution time
```

## ğŸš€ Starting the Server

### Web Dashboard (Recommended)

```bash
# 1. Navigate to src directory
cd src

# 2. Start the server
python web/dashboard.py
```

**You'll see:**
```
============================================================
Starting Configurable Agent Web Dashboard
============================================================
Initializing components...
Loading vector index...
Initializing baseline agent...
Initializing configurable agent...
Connecting to Neo4j (optional)...

============================================================
Dashboard ready!
Open your browser and go to: http://localhost:5000
============================================================
 * Running on http://0.0.0.0:5000
```

**Then:**
1. Open browser: `http://localhost:5000`
2. Enter question in the form
3. Optionally provide expected answer
4. Click "Get Answer"
5. View results in real-time

### Command Line Interface

```bash
cd src
python -m evaluation.interactive_eval
```

**You'll see:**
```
============================================================
Configurable Agent Interactive Evaluation
============================================================
Initializing components (this may take a moment)...
Loading vector index...
Initializing baseline agent...
Initializing configurable agent...
Connecting to Neo4j (optional)...

============================================================
Ready! Enter questions to evaluate.
Type 'exit' or 'quit' to stop, or Ctrl+C to interrupt.
============================================================

Enter your question (or 'exit' to quit):
```

## ğŸ“ File Structure & Responsibilities

```
src/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ base_config.yaml          # Agent configuration
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ model_client.py            # Ollama API wrapper
â”‚   â”œâ”€â”€ data_loader.py             # Loads & formats CSV datasets
â”‚   â”œâ”€â”€ vector_index.py            # FAISS similarity search
â”‚   â””â”€â”€ graph_logger.py            # Neo4j logging (optional)
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ planner.py                 # Breaks questions into steps
â”‚   â”œâ”€â”€ reasoner.py                # LLM reasoning via Ollama
â”‚   â”œâ”€â”€ memory.py                  # Stores Q&A pairs
â”‚   â”œâ”€â”€ tools.py                    # Math evaluation
â”‚   â”œâ”€â”€ reflection.py              # Answer quality evaluation
â”‚   â”œâ”€â”€ baseline_agent.py         # Simple direct agent
â”‚   â””â”€â”€ agent_controller.py        # Orchestrates all components
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ metrics.py                 # BLEU/ROUGE calculation
â”‚   â””â”€â”€ interactive_eval.py        # CLI evaluation interface
â”‚
â””â”€â”€ web/
    â””â”€â”€ dashboard.py               # Web interface & API
```

## ğŸ”„ How Components Work Together

1. **Initialization** (happens once):
   - Load datasets â†’ Build vector index
   - Initialize agents (baseline + configurable)
   - Connect to Neo4j (optional)

2. **Question Processing** (per question):
   - Query vector index for similar examples
   - Run baseline agent (fast)
   - Run configurable agent (multi-stage)
   - Calculate metrics (if expected provided)
   - Log to Neo4j (if available)

3. **Output**:
   - Display all results
   - Show metrics
   - Show similar examples
   - Show execution time

## ğŸ“ Key Concepts

### Vector Embeddings
- Text â†’ Numbers (384 dimensions)
- Similar text = similar numbers
- Enables fast similarity search

### FAISS Index
- Fast similarity search library
- L2 distance (Euclidean)
- Finds closest vectors efficiently

### Ollama Integration
- Local LLM server
- No GPU required (CPU works)
- Easy model switching

### Component Modularity
- Each component is independent
- Can be enabled/disabled via config
- Easy to extend or modify

## ğŸ’¡ Tips

1. **First run is slow**: Loading datasets and building index takes time
2. **Subsequent questions are fast**: Components are reused
3. **Expected answer optional**: Metrics only calculated if provided
4. **Neo4j optional**: System works without it
5. **Model switching**: Change in config file, restart needed











